{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Frist_Look.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "jxiUadDiVFnr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IC1wtztfVFn7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jd2ff-4fVFoF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "edd356a8-1ae2-4704-c66b-853d444f62c1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1516888539773,
          "user_tz": -120,
          "elapsed": 1171,
          "user": {
            "displayName": "ahmed osama",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108653885218413593337"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ep2d_QcxVFoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "6piwzfBsVFof",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#init Weight\n",
        "def init_weight(shape,name_W):\n",
        "    init_rand_dist = tf.truncated_normal(shape,stddev=0.1)\n",
        "    return tf.Variable(init_rand_dist,name=name_W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TiRY64DJVFon",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#init Bias\n",
        "def init_bias(shape,name_b):\n",
        "    init_bias_vals = tf.constant(value=0.1,shape=shape)\n",
        "    return tf.Variable(initial_value=init_bias_vals,name=name_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Evoe0kZrVFos",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Conv2D\n",
        "\n",
        "def conv2d(X,W,name_conv):\n",
        "    # X --> [batch,H,W,Channels]\n",
        "    # W --> [filter H , filter W , Channel In , Channel Out]\n",
        "    \n",
        "    \n",
        "    \n",
        "    return tf.nn.conv2d(X,W,strides=[1,1,1,1],padding='SAME',name=name_conv)\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXejT1t_VFow",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Pooling\n",
        "\n",
        "\n",
        "\n",
        "def max_pooling_2by2(X):\n",
        "    # X --> [batch,H,W,Channels]\n",
        "    \n",
        "    return tf.nn.max_pool(X,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-UtrXRaVFo2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Convolutional Layes\n",
        "\n",
        "def convolutional_layer(input_x, shape,name_W,name_b,name_conv):\n",
        "    W = init_weight(shape = shape,name_W=name_W)\n",
        "    b = init_bias(shape = [shape[3]],name_b = name_b)\n",
        "    \n",
        "    \n",
        "    return tf.nn.relu(conv2d(input_x,W, name_conv =name_conv) + b )\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FeoMNgZmVFo6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Normal Layer (fully connected Layer)\n",
        "\n",
        "def normal_full_layer(input_layer,size,name_W,name_b):\n",
        "    \n",
        "    input_size = int(input_layer.get_shape()[1])\n",
        "    W = init_weight([input_size,size],name_W=name_W)\n",
        "    b = init_bias([size],name_b=name_b)\n",
        "    \n",
        "    return tf.matmul(input_layer , W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K5DsdQ8jVFpA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building Model "
      ]
    },
    {
      "metadata": {
        "id": "mc3MAWsJVFpC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32,shape=[None,784])\n",
        "y_true = tf.placeholder(tf.float32,shape=[None,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcayJX85VFpK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_image = tf.reshape(X,[-1,28,28,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OK_Rvmo_046r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "HLczOXmtVFpT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Layers\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GzvMsMXYVFpU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "convo_1 = convolutional_layer( X_image , shape = [6,6,1,32] , name_W = \"W_conv1\" , name_b = \"bias_Conv1\" , name_conv = \"Conv_1\")\n",
        "convo_1_pooling = max_pooling_2by2(convo_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hjFIVzgcVFpb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "convo_2 = convolutional_layer( convo_1_pooling , shape = [6,6,32,64] , name_W = \"W_conv2\" , name_b = \"bias_Conv2\" , name_conv = \"Conv_2\")\n",
        "convo_2_pooling = max_pooling_2by2(convo_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xDKKBaf2VFpj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
        "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024,name_W=\"full_layer_W\",name_b=\"full_layer_b\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F452MdwtVFpq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " # Dropout"
      ]
    },
    {
      "metadata": {
        "id": "iymKJxNlVFpu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "hold_prob = tf.placeholder(tf.float32)\n",
        "full_one_dropot = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OewjAILxVFp0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = normal_full_layer(full_one_dropot,10,name_W = 'out_W',name_b='out_b' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LSu_qJixVFp6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ]
    },
    {
      "metadata": {
        "id": "9G_3X9udVFp8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true , logits= y_pred ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wcEDfpO9VFqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# optimizer"
      ]
    },
    {
      "metadata": {
        "id": "mklRZe80VFqK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gUrdA2IVFqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Session Running"
      ]
    },
    {
      "metadata": {
        "id": "z18tQSw5VFqR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLSQ52utVFqZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 42
            },
            {
              "item_id": 102
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 4355
        },
        "outputId": "820f2fd5-8912-445f-dc9c-8ddb9ecfdeb9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1516890127365,
          "user_tz": -120,
          "elapsed": 1570394,
          "user": {
            "displayName": "ahmed osama",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108653885218413593337"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "steps = 5000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    \n",
        "    print (tf.all_variables())\n",
        "    \n",
        "    \n",
        "   \n",
        "    for i in range (steps) :   \n",
        "        batch_x , batch_y = mnist.train.next_batch(50)\n",
        "        #print(convo_2_flat.eval(feed_dict={X:batch_x, y_true:batch_y, hold_prob:1.0}).shape)\n",
        "\n",
        "        \n",
        "        sess.run(train,feed_dict={X:batch_x,y_true:batch_y,hold_prob:0.5})\n",
        "        \n",
        "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
        "        if i%100 == 0:\n",
        "            \n",
        "            print('Currently on step {}'.format(i))\n",
        "            print('Accuracy is:')\n",
        "            # Test the Train Model\n",
        "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "\n",
        "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "            print(sess.run(acc,feed_dict={X:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
        "            print('\\n')\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "        "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-a1bbc700d521>:7: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Please use tf.global_variables instead.\n",
            "[<tf.Variable 'W_conv1:0' shape=(6, 6, 1, 32) dtype=float32_ref>, <tf.Variable 'bias_Conv1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'W_conv2:0' shape=(6, 6, 32, 64) dtype=float32_ref>, <tf.Variable 'bias_Conv2:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'full_layer_W:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'full_layer_b:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'out_W:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'out_b:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'W_conv1/Adam:0' shape=(6, 6, 1, 32) dtype=float32_ref>, <tf.Variable 'W_conv1/Adam_1:0' shape=(6, 6, 1, 32) dtype=float32_ref>, <tf.Variable 'bias_Conv1/Adam:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'bias_Conv1/Adam_1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'W_conv2/Adam:0' shape=(6, 6, 32, 64) dtype=float32_ref>, <tf.Variable 'W_conv2/Adam_1:0' shape=(6, 6, 32, 64) dtype=float32_ref>, <tf.Variable 'bias_Conv2/Adam:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'bias_Conv2/Adam_1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'full_layer_W/Adam:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'full_layer_W/Adam_1:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'full_layer_b/Adam:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'full_layer_b/Adam_1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'out_W/Adam:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'out_W/Adam_1:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'out_b/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'out_b/Adam_1:0' shape=(10,) dtype=float32_ref>]\n",
            "Currently on step 0\n",
            "Accuracy is:\n",
            "0.1491\n",
            "\n",
            "\n",
            "Currently on step 100\n",
            "Accuracy is:\n",
            "0.932\n",
            "\n",
            "\n",
            "Currently on step 200\n",
            "Accuracy is:\n",
            "0.9547\n",
            "\n",
            "\n",
            "Currently on step 300\n",
            "Accuracy is:\n",
            "0.9709\n",
            "\n",
            "\n",
            "Currently on step 400\n",
            "Accuracy is:\n",
            "0.9729\n",
            "\n",
            "\n",
            "Currently on step 500\n",
            "Accuracy is:\n",
            "0.9745\n",
            "\n",
            "\n",
            "Currently on step 600\n",
            "Accuracy is:\n",
            "0.9795\n",
            "\n",
            "\n",
            "Currently on step 700\n",
            "Accuracy is:\n",
            "0.9817\n",
            "\n",
            "\n",
            "Currently on step 800\n",
            "Accuracy is:\n",
            "0.9763\n",
            "\n",
            "\n",
            "Currently on step 900\n",
            "Accuracy is:\n",
            "0.982\n",
            "\n",
            "\n",
            "Currently on step 1000\n",
            "Accuracy is:\n",
            "0.9855\n",
            "\n",
            "\n",
            "Currently on step 1100\n",
            "Accuracy is:\n",
            "0.9825\n",
            "\n",
            "\n",
            "Currently on step 1200\n",
            "Accuracy is:\n",
            "0.9832\n",
            "\n",
            "\n",
            "Currently on step 1300\n",
            "Accuracy is:\n",
            "0.9843\n",
            "\n",
            "\n",
            "Currently on step 1400\n",
            "Accuracy is:\n",
            "0.9865\n",
            "\n",
            "\n",
            "Currently on step 1500\n",
            "Accuracy is:\n",
            "0.9848\n",
            "\n",
            "\n",
            "Currently on step 1600\n",
            "Accuracy is:\n",
            "0.9859\n",
            "\n",
            "\n",
            "Currently on step 1700\n",
            "Accuracy is:\n",
            "0.9866\n",
            "\n",
            "\n",
            "Currently on step 1800\n",
            "Accuracy is:\n",
            "0.9863\n",
            "\n",
            "\n",
            "Currently on step 1900\n",
            "Accuracy is:\n",
            "0.9871\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Currently on step 2000\n",
            "Accuracy is:\n",
            "0.9898\n",
            "\n",
            "\n",
            "Currently on step 2100\n",
            "Accuracy is:\n",
            "0.9887\n",
            "\n",
            "\n",
            "Currently on step 2200\n",
            "Accuracy is:\n",
            "0.9889\n",
            "\n",
            "\n",
            "Currently on step 2300\n",
            "Accuracy is:\n",
            "0.9905\n",
            "\n",
            "\n",
            "Currently on step 2400\n",
            "Accuracy is:\n",
            "0.9886\n",
            "\n",
            "\n",
            "Currently on step 2500\n",
            "Accuracy is:\n",
            "0.9883\n",
            "\n",
            "\n",
            "Currently on step 2600\n",
            "Accuracy is:\n",
            "0.9874\n",
            "\n",
            "\n",
            "Currently on step 2700\n",
            "Accuracy is:\n",
            "0.9906\n",
            "\n",
            "\n",
            "Currently on step 2800\n",
            "Accuracy is:\n",
            "0.9885\n",
            "\n",
            "\n",
            "Currently on step 2900\n",
            "Accuracy is:\n",
            "0.9876\n",
            "\n",
            "\n",
            "Currently on step 3000\n",
            "Accuracy is:\n",
            "0.9865\n",
            "\n",
            "\n",
            "Currently on step 3100\n",
            "Accuracy is:\n",
            "0.9897\n",
            "\n",
            "\n",
            "Currently on step 3200\n",
            "Accuracy is:\n",
            "0.9882\n",
            "\n",
            "\n",
            "Currently on step 3300\n",
            "Accuracy is:\n",
            "0.9893\n",
            "\n",
            "\n",
            "Currently on step 3400\n",
            "Accuracy is:\n",
            "0.989\n",
            "\n",
            "\n",
            "Currently on step 3500\n",
            "Accuracy is:\n",
            "0.9905\n",
            "\n",
            "\n",
            "Currently on step 3600\n",
            "Accuracy is:\n",
            "0.99\n",
            "\n",
            "\n",
            "Currently on step 3700\n",
            "Accuracy is:\n",
            "0.9903\n",
            "\n",
            "\n",
            "Currently on step 3800\n",
            "Accuracy is:\n",
            "0.9888\n",
            "\n",
            "\n",
            "Currently on step 3900\n",
            "Accuracy is:\n",
            "0.9899\n",
            "\n",
            "\n",
            "Currently on step 4000\n",
            "Accuracy is:\n",
            "0.9906\n",
            "\n",
            "\n",
            "Currently on step 4100\n",
            "Accuracy is:\n",
            "0.9895\n",
            "\n",
            "\n",
            "Currently on step 4200\n",
            "Accuracy is:\n",
            "0.9902\n",
            "\n",
            "\n",
            "Currently on step 4300\n",
            "Accuracy is:\n",
            "0.9898\n",
            "\n",
            "\n",
            "Currently on step 4400\n",
            "Accuracy is:\n",
            "0.9887\n",
            "\n",
            "\n",
            "Currently on step 4500\n",
            "Accuracy is:\n",
            "0.9898\n",
            "\n",
            "\n",
            "Currently on step 4600\n",
            "Accuracy is:\n",
            "0.99\n",
            "\n",
            "\n",
            "Currently on step 4700\n",
            "Accuracy is:\n",
            "0.991\n",
            "\n",
            "\n",
            "Currently on step 4800\n",
            "Accuracy is:\n",
            "0.9898\n",
            "\n",
            "\n",
            "Currently on step 4900\n",
            "Accuracy is:\n",
            "0.9872\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E4AVuhYKYWaL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}